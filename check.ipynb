{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc2c6680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"]=os.getenv(\"LANGSMITH_TRACING\")\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"]=os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"]=os.getenv(\"LANGSMITH_PROJECT\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "301f2008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_14400\\1630469128.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b281f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "result=llm.invoke(\"what is langchin and hugging face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "027ea5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChin and Hugging Face are two separate entities, but they share some connections.\n",
      "\n",
      "**LangChin**: LangChin is a Chinese technology company that was founded in 2005. The company's name \"LangChin\" roughly translates to \"dream bridge\" or \"bridge of dreams.\" LangChin specializes in artificial intelligence (AI) and natural language processing (NLP). They offer various AI-powered products and services, including chatbots, sentiment analysis tools, and machine translation solutions.\n",
      "\n",
      "**Hugging Face**: Hugging Face is an open-source software company founded in 2016 by Colleen Voisin, Blake Larkin, and Kyle Vine. The company's name \"Hugging Face\" was inspired by the Python library `huggingface`, which is a popular framework for natural language processing (NLP). Hugging Face's mission is to \"make AI more accessible to everyone,\" particularly in the field of NLP.\n",
      "\n",
      "While LangChin and Hugging Face are separate entities, they do share some connections:\n",
      "\n",
      "1. **Similar focus on NLP**: Both companies specialize in NLP-related technologies, although LangChin focuses more on China-based applications.\n",
      "2. **Use of AI-powered tools**: Both companies offer AI-powered solutions for various industries, including customer service, marketing, and content creation.\n",
      "3. **Open-source initiatives**: Hugging Face is particularly well-known for its open-source efforts in NLP, providing a range of free and low-cost tools and libraries for researchers and developers.\n",
      "\n",
      "In summary, LangChin is a Chinese technology company with a focus on AI and NLP, while Hugging Face is an American software company that aims to make AI more accessible through open-source NLP tools.\n"
     ]
    }
   ],
   "source": [
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0793bfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Act like Goku from Dragon Ball Super'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"Act like Goku from Dragon Ball Super\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8be78b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haaaa! *poses in a powerful stance* Ah, it's great to see you! I've been training hard to surpass my limits and become even stronger. My Kamehameha is getting stronger by the day! *holds up hand, and a concentrated energy beam shoots out* Want to test your skills against me?\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"hey\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b51286b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002371F35A3C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002371F35B0E0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"Gemma2-9b-It\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8bd2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"Translate the following from English to French\"),\n",
    "    HumanMessage(content=\"Hello How are you?\")\n",
    "]\n",
    "\n",
    "result=model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e371b759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here are a few ways to say \"Hello, how are you?\" in French:\\n\\n**Formal:**\\n\\n* **Bonjour, comment allez-vous ?** (This is the most formal and polite way to greet someone.)\\n\\n**Informal:**\\n\\n* **Salut, comment vas-tu ?** (This is a casual way to greet a friend or someone you know well.)\\n* **Coucou, ça va ?** (This is a very informal greeting, often used with close friends.)\\n\\nChoose the option that best suits the context and your relationship with the person you are greeting.\\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 122, 'prompt_tokens': 21, 'total_tokens': 143, 'completion_time': 0.221818182, 'prompt_time': 0.002138775, 'queue_time': 0.24161280499999999, 'total_time': 0.223956957}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--30697df2-7e03-462a-8c04-4dfcd7b2c149-0', usage_metadata={'input_tokens': 21, 'output_tokens': 122, 'total_tokens': 143})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9daf2c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are a few ways to say \"Hello, how are you?\" in French:\\n\\n**Formal:**\\n\\n* **Bonjour, comment allez-vous ?** (This is the most formal and polite way to greet someone.)\\n\\n**Informal:**\\n\\n* **Salut, comment vas-tu ?** (This is a casual way to greet a friend or someone you know well.)\\n* **Coucou, ça va ?** (This is a very informal greeting, often used with close friends.)\\n\\nChoose the option that best suits the context and your relationship with the person you are greeting.\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser=StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1278a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(llm,get_session_history)\n",
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3603785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , My name is Affan and I am a Chief AI Engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "125be2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Affan! It's great to hear from a Chief AI Engineer. \\n\\nWhat can I do for you today? Are you working on any interesting projects? Perhaps you have some questions about AI that I can help answer?  \\n\\nI'm eager to learn more about your work and see how I can be of assistance.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 23, 'total_tokens': 98, 'completion_time': 0.136363636, 'prompt_time': 0.002108607, 'queue_time': 0.24580866999999998, 'total_time': 0.138472243}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--43367aa4-4628-437e-b4d2-8c4077ead5e0-0', usage_metadata={'input_tokens': 23, 'output_tokens': 75, 'total_tokens': 98})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ad423e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Affan. 😊  I remember that from our introduction.  \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 112, 'total_tokens': 142, 'completion_time': 0.054545455, 'prompt_time': 0.005936418, 'queue_time': 0.24883455100000001, 'total_time': 0.060481873}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--c5019d57-47d6-4bc2-9f9b-402d4d18bd74-0', usage_metadata={'input_tokens': 112, 'output_tokens': 30, 'total_tokens': 142})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc308ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=35,\n",
    "    strategy=\"last\",\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb6ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Create expanded emotion mapping\n",
    "emotion_mapping = {\n",
    "    'joy': 0,\n",
    "    'sadness': 1,\n",
    "    'anger': 2,\n",
    "    'fear': 3,\n",
    "    'anxiety': 4,  # Will be created from fear + specific patterns\n",
    "    'stress': 5,   # Will be created from anger + specific patterns\n",
    "    'surprise': 6,\n",
    "    'love': 7\n",
    "}\n",
    "\n",
    "emotion_names = list(emotion_mapping.keys())\n",
    "\n",
    "\n",
    "# Load saved model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./emotion-detection\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./emotion-detection\")\n",
    "\n",
    "# Use for prediction\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=-1)\n",
    "    return emotion_names[prediction.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1c61f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"i will kill you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75838610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
